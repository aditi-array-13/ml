!pip install scikit-learn
!pip install matplotlib seaborn

# Import necessary libraries
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns

# Step 1: Load the dataset
url = 'https://media.geeksforgeeks.org/wp-content/uploads/Wine.csv'
data = pd.read_csv(url)
data

# Filter the dataset to include only red and white wines (assuming these are represented by specific Customer_Segment values)
# Example: Let's assume '1' represents red wine and '2' represents white wine
red_white_data = data[data['Customer_Segment'].isin([1, 2])]

# Step 2: Preprocess the data
# Extract features (all columns except the target variable 'Customer_Segment')
features = red_white_data.columns[1:]

# Separate out the features and the target variable
X = data[features]
y = data['Customer_Segment']

# Standardize the data (important for PCA)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Step 3: Apply PCA
# Instantiate PCA and fit the data
pca = PCA(n_components=2)  # Let's reduce to 2 components for visualization
principal_components = pca.fit_transform(X_scaled)

# Create a DataFrame with the principal components
principal_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])

# Add the target variable to the DataFrame
principal_df['Customer_Segment'] = y

# Step 4: Visualize the results
# Plot the principal components
plt.figure(figsize=(10, 7))
sns.scatterplot(data=principal_df, x='PC1', y='PC2', hue='Customer_Segment', palette='Set1', alpha=0.7)
plt.title('PCA of Wine Dataset (Red vs White)')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.show()

# Display explained variance ratio
explained_variance = pca.explained_variance_ratio_
print(f"Explained variance by the 2 principal components: {explained_variance}")
print(f"Total explained variance: {sum(explained_variance)}")
